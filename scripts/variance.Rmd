---
title: "Variance analysis"
author: "Kimberly Olney, Ph.D."
date: "10/21/2024"
output:
  html_document:
    df_print: paged
  pdf_document: default
params:
  args: myarg
---
# Setup
```{r setup, message=FALSE, warning=FALSE, tidy=TRUE}
knitr::opts_knit$set(root.dir = ".")
```

# User defined variables
sourcing file_paths_and_colours will load the libraries and user defined variables for colors of the graphs 
```{r set_variables, message=FALSE, warning=FALSE, tidy=TRUE}
source(here::here("scripts", "file_paths_and_colours.R"))
```

# Read in DGE object & metadata
```{r dge}
dge.filtered.norm <- readRDS("../../rObjects/dge.filtered.norm.rds")
dge.filtered.norm$samples$batch <- sub("^.*_FC([^_]+)_.*$", "\\1", dge.filtered.norm$samples$RNA.config.ID)
# check batch
table(dge.filtered.norm$samples$batch)
dge.filtered.norm$samples$batch <- factor(dge.filtered.norm$samples$batch)
dge.filtered.norm$samples$APOE <- factor(dge.filtered.norm$samples$APOE)

info <- as.data.frame(dge.filtered.norm$samples)
genes <- dge.filtered.norm$genes
gene_name <- genes$gene_name
saveRDS(gene_name, file ="../../rObjects/gene_tables/gene_options.rds")
```

# Add biomarker expression to dge metadata 
```{r genes_lcpm}
genes <- dge.filtered.norm$genes # gene information 
lcpm <- edgeR::cpm(dge.filtered.norm$counts, log = TRUE) # obtain log CPM counts

cpm <- edgeR::cpm(dge.filtered.norm$counts, log = FALSE)
write.table(cpm, "../../results/star/counts/cpm.tsv", quote = FALSE, sep = "\t")
dim(cpm)

lcpm <- edgeR::cpm(dge.filtered.norm$counts, log = TRUE)
write.table(lcpm, "../../results/star/counts/lcpm.tsv", quote = FALSE, sep = "\t")
write.table(info, "../../results/star/counts/metadata.tsv", quote = FALSE, sep = "\t")
```

```{r biomarker_expression}
biomarkers <- c("ENO2", "GFAP", "OLIG2", "CD34", "P2RY12")

for (i in biomarkers) {
  biomarker <- subset(genes, gene_name == i) # gene of interest 
  biomarker_counts <- subset(lcpm, rownames(lcpm) %in% biomarker)
  biomarker_melt <- reshape2::melt(biomarker_counts) # reshape data 
  # rename columns to merge with metadata 
  names(biomarker_melt)[names(biomarker_melt) == "value"] <- i 
  # rename columns to merge with metadata 
  names(biomarker_melt)[names(biomarker_melt) == "Var2"] <- "NPID" 
  names(biomarker_melt)[names(biomarker_melt) == "Var1"] <- "gene_id"
  biomarker_melt$gene_id <- NULL
  assign(paste0(i),biomarker_melt)
}

# add gene expression values into one dataframe 
# put all data frames into list
df_list <- list(ENO2, OLIG2, CD34, P2RY12, GFAP)

# merge all data frames in list
cell_biomarker_lcpm <- df_list %>% reduce(full_join, by='NPID')
write.table(cell_biomarker_lcpm, "../../rObjects/gene_tables/cell_biomarker_cpm.txt", quote = FALSE, sep = "\t")
```

# Scale data
rescaling a predictor in a regression has absolutely no effect on the magnitude of the relation being studiedâ€”the slope itself will not change its steepness, nor will the p-values or variance explained be changed. Rescaling is merely a means of communicating the nature of the regression line in different, hopefully more intuitive language.
```{r scale}
df <- merge(cell_biomarker_lcpm, info, by = "NPID")
scaled.info <-
  df[c(
    "RIN",
    "Age",
    "PCT_CODING_BASES",
    "PCT_INTERGENIC_BASES",
    "PCT_INTRONIC_BASES",
    "APOE_E4_allele_count", 
    "ENO2", 
    "GFAP", 
    "OLIG2", 
    "CD34", 
    "P2RY12",
    "Brain.wt"
  )] %>% scale()
scaled.info.df <- as.data.frame(scaled.info)
# remove columns with unscaled data 
df <- (subset(df, select = -c(RIN, Age, PCT_CODING_BASES, PCT_INTRONIC_BASES, APOE_E4_allele_count, ENO2, GFAP, OLIG2, CD34, P2RY12, Brain.wt)))
# Add scaled information to the metadata called "info"
info_with_scale <- cbind(df, scaled.info.df)
```

```{r}
all.equal(dge.filtered.norm$samples$NPID, as.character(info_with_scale$NPID))
# replace sample information with the updated info that includes biomakrer expression
dge.filtered.norm$samples <- info_with_scale
rownames(info_with_scale) <- info_with_scale$NPID
```

Voom transform counts to use for BIC 
```{r voom, warning=FALSE}
formula <- (~ 0 + TYPE)
voom_with_weights <-
  variancePartition::voomWithDreamWeights(
    counts = dge.filtered.norm$counts,
    formula = formula,
    data = dge.filtered.norm$samples,
    BPPARAM = BiocParallel::SnowParam(cores),
    plot = TRUE
  )
path <- paste0("../../results/", tool, "/voom/", condition, ".raw.voom")
saveToPDF(paste0(path, ".pdf"), width = 6, height = 4)
voomCounts <- voom_with_weights$E
counts_voom <- as.matrix(voomCounts)
```

# Fit variance 
variancePartition quantifies and interprets multiple sources of biological and technical variation in gene expression experiments. The package a linear mixed model to quantify variation in gene expression attributable to individual, tissue, time point, or technical variables.
```{r varpart}
form_varPart <- ~ TYPE +
  batch +
  sex_inferred + 
  PCT_CODING_BASES +
  PCT_INTERGENIC_BASES + 
  PCT_INTRONIC_BASES +
  RIN +
  ENO2 
# fit model and extract variance percents
varPart <- fitExtractVarPartModel(voomCounts, form_varPart, info_with_scale)
```

```{r}
setnames(varPart, old = c('batch','sex_inferred','PCT_INTRONIC_BASES','PCT_CODING_BASES','PCT_INTERGENIC_BASES'), 
         new = c('Batch','Sex','% intronic','% coding','% intergenic'))
setnames(varPart, old = c('TYPE'), 
         new = c('Group'))

plotVarPart(sortCols(varPart), label.angle = 80) +
      theme(
             axis.title.x = element_text(size = 9),
             axis.text.x = element_text(size = 9),
             axis.title.y = element_text(size = 9),
             axis.text.y = element_text(size = 9)) 
path <-
  paste0(
    "../../results/",
    tool,
    "/varpart/",
    condition,
    ".finalmodel.varpart"
  )
saveToPDF(paste0(path, ".pdf"), width = 8.5, height = 5)
saveRDS(varPart,   paste0("../../rObjects/finalmodel.varpart.rds"))

# sort variables (i.e. columns) by median fraction # of variance explained
vp <- sortCols( varPart )
# Bar plot of variance fractions for the first 10 genes plotPercentBars( vp[1:10,] )
plotPercentBars( vp[1:10,] )

varPart$gene_id <- rownames(varPart)
# merge with gene information to get gene names for gene_id
variance_explained <- merge(varPart, genes, by = "gene_id")

# Reorder columns
variance_explained_reorder <- variance_explained[, c(1,21,11,2:10)]

# remove unnecessary columns 
write.table(
  variance_explained_reorder,
  paste0(
    "../../results/",
    tool ,
    "/varpart/",
    condition,
    ".finalmodel.variance.explained.tsv"
  ),
  sep = "\t",
  quote = FALSE
)
```

# CCA 
```{r}
form <- ~ TYPE + 
  sex_inferred + 
  batch +
  PCT_CODING_BASES +
  PCT_INTERGENIC_BASES + 
  PCT_INTRONIC_BASES +
  RIN +
  ENO2 

# Compute Canonical Correlation Analysis (CCA) # between all pairs of variables
# returns absolute correlation value
C = canCorPairs( form, info_with_scale)
# Plot correlation matrix
plotCorrMatrix( C )

path <-
  paste0(
    "../../results/",
    tool,
    "/varpart/",
    condition,
    ".finalmodel.CCA"
  )
saveToPDF(paste0(path, ".pdf"), width = 8, height = 8)
```

# BIC with forward stepwise regression
First, we will scale some of the continuous variables. 
In regression, it is often recommended to scale the features so that the predictors have a mean of 0. This makes it easier to interpret the intercept term as the expected value of Y when the predictor values are set to their means.
scale is generic function whose default method centers and/or scales the columns of a numeric matrix.

Secondly, obtian voom$E counts to use in the BIC. 
Finally, perform forwards stepwise regression Bayesian information criterion (BIC) to determine the best model. 
see: https://rdrr.io/github/GabrielHoffman/mvIC/man/mvIC_fit.html 
```{r BIC, eval = FALSE}
baseFormula <- ~ (1 | TYPE)
# Combine responses on *rows*
# Add brain weight, brain weight and sex interaction, Age and sex interaction 
Y = with(
  info,
  rbind(
    sex_inferred,
    flowcell_and_lane,
    scaled.info.df$RIN,
    scaled.info.df$Age,
    scaled.info.df$PCT_CODING_BASES,
    scaled.info.df$PCT_INTERGENIC_BASES,
    scaled.info.df$PCT_INTRONIC_BASES, 
    scaled.info.df$ENO2, 
    sex_inferred:Brain.wt
  )
)

rownames(Y) <-
  c(
    "sex_inferred",
    "flowcell_and_lane",
    "RIN",
    "Age",
    "PCT_CODING_BASES",
    "PCT_INTERGENIC_BASES",
    "PCT_INTRONIC_BASES",
    "ENO2",
    "sex_inferred:Brain.wt"
  )
# variables to consider in the model
# categorical variables must be modeled using (1|)
variables = c(
  "(1|sex_inferred)",
  "(1|flowcell_and_lane)",
  "RIN",
  "Age",
  "PCT_CODING_BASES",
  "PCT_INTERGENIC_BASES",
  "PCT_INTRONIC_BASES",
  "ENO2",
  "sex_inferred:Brain.wt"
)

# fit forward stepwise regression starting
bestModel_voomcounts = mvForwardStepwise(voomCounts,
                                         baseFormula,
                                         data = info_with_scale,
                                         variables = variables)
bestModel_voomcounts
```

  
# Design matrix
```{r design}
design <-
  model.matrix(~ 0 + 
      TYPE + 
      sex_inferred + 
      batch + 
      RIN +
      PCT_CODING_BASES +
      PCT_INTERGENIC_BASES + 
      PCT_INTRONIC_BASES +
      ENO2,
    dge.filtered.norm$samples
  )

colnames(design) <-
  c(
    CONTROL,
    PA,
    AD,
    LBD,
    "sex",
    "Batch1",
    "Batch2",
    "Batch3",
    "Batch4",
    "Batch5",
    "Batch6",
    "Batch7",
    "RIN",
    "PCT_CODING_BASES", 
    "PCT_INTERGENIC_BASES", 
    "PCT_INTRONIC_BASES",
    "ENO2"
  )
```

# Voom
When the library sizes are quite variable between samples, then the voom approach is theoretically more powerful than limma-trend. 
The voom method estimates the mean-variance relationship of the log-counts.
Generates a precision weight for each observation and enters these into the limma empirical Bayes analysis pipeline.
```{r voom_BIC}
form <- (
  ~ 0 +
      TYPE + 
      sex_inferred + 
      batch + 
      RIN +
      PCT_CODING_BASES +
      PCT_INTERGENIC_BASES + 
      PCT_INTRONIC_BASES +
      ENO2
)

voom_cov <-
  variancePartition::voomWithDreamWeights(
    counts = dge.filtered.norm$counts,
    formula = form,
    data = dge.filtered.norm$samples,
    BPPARAM = BiocParallel::SnowParam(cores),
    plot = TRUE
  )
path <-
  paste0("../../results/",
         tool,
         "/voom/",
         condition,
         ".voom.finalmodel")
saveToPDF(paste0(path, ".pdf"), width = 6, height = 4)
voomCounts <- voom_cov$E
```

# Contrast plot
### pairwise TYPE 
```{r contrasts}
# fits linear model for each gene given a series of arrays
fit <- lmFit(voom_cov, design)
coef.fit <- fit$coefficients

contrasts <- makeContrasts(
  LBDvsControl = LBD - CONTROL,
  LBDvsAD = LBD - AD,
  LBDvsPA = LBD - PA,
  ADvsControl = AD - CONTROL, 
  PAvsControl = PA - CONTROL,
  ADvsPA = AD - PA, 
  levels = colnames(design))
head(contrasts)

# save contrast names
allComparisons <- colnames(contrasts)
allComparisons # check

# run contrast analysis
vfit <- contrasts.fit(fit, contrasts = contrasts)

# Compute differential expression based on the empirical Bayes moderation of the
# standard errors towards a common value.
# The logCPM values can then be used in any standard limma pipeline, using the trend=TRUE
# argument when running eBayes or treat. For example:
veBayesFit <- eBayes(vfit, trend = TRUE, robust=TRUE)
plotSA(veBayesFit, main = "Final Model: Mean-variance Trend")
path <-
  paste0("../../results/",
         tool,
         "/voom/",
         condition,
         ".voom.eBayes.finalmodel")
saveToPDF(paste0(path, ".pdf"), width = 9, height = 5)
```

# DEGs summary
```{r DGE_summary}
pval <- 0.05
lfc.cutoff <- 0.25

sumTable <- 
  summary(decideTests(
    veBayesFit,  # object
    adjust.method = "BH", # by default the method = "separate"
    p.value = pval,
    lfc = lfc.cutoff  # numeric, minimum absolute log2-fold change required
  ))

print(paste0(" FDRq < ", pval,
             " & absolute log2-fold change > ", lfc.cutoff))
sumTable
write.table(sumTable, 
            paste0("../../results/", tool, "/DEGs/", condition, ".DEGs.summary.txt"), 
            quote = FALSE, sep = "\t")
```
# Add gene information to DEGs
reformat genes table to only include relevant information
```{r}
genes_relevant <- dplyr::select(genes, 1:4,10:12)
```

Check 
```{r DGE_check, eval=FALSE}
test <- topTable(
  veBayesFit, 
  coef = "PAvsControl",  
  n = Inf, 
  p.value = 1,
  lfc = 0, 
  sort.by = "P", 
  genelist = genes_relevant, 
  confint = TRUE # column of confidence interval 
    )
#head(test, 20)
#subset(test, gene_name == "SNCB") 
```
# cool map
```{r}
LBDvsControl <- topTable(veBayesFit, coef = 'LBDvsAD', p.value = 0.05, adjust.method = 'fdr',
                  number = Inf, genelist = genes_relevant)
LBDvsControl$gene_id
up <- LBDvsControl$gene_id[LBDvsControl$logFC > .25][1:15]
down <- LBDvsControl$gene_id[LBDvsControl$logFC < -.25][1:15]
select <- c(up, down)
coolmap(voom_cov[select,])
```
# Save objects
```{r save_voom}
saveRDS(veBayesFit, file = paste0("../../rObjects/", condition, ".veBayesFit.rds"))
saveRDS(voomCounts, file = paste0("../../rObjects/", condition, ".voomCountsMatrix.rds"))
```

# Output DEG tables
```{r DGE_output}
coef <- 1

for (i in allComparisons) {
  vTopTableAll <- topTable(
    veBayesFit, 
    coef = coef,  
    n = Inf, 
    p.value = 1,
    lfc = 0, 
    sort.by = "P", 
    genelist = genes_relevant, 
    confint = TRUE # column of confidence interval 
    )
    saveRDS(vTopTableAll, file = 
            paste0("../../rObjects/gene_tables/", condition, "_", 
                   i,"_gene_table.rds"))
  path <- paste0("../../results/", tool, "/DEGs/", condition, "_", 
  i, "_gene_DEGs_FDRq1.00.txt", sep = "") 
  write.table(
    vTopTableAll,
    path,
    sep = "\t",
    row.names = FALSE,
    quote = FALSE
  )
  # p < 0.05, log2fc > 0
  vTopTable1 <-
    topTable( 
      veBayesFit,  
      coef = coef,  
      n = Inf, 
      p.value = pval,
      lfc = lfc.cutoff,
      genelist = genes_relevant, 
      confint = TRUE # column of confidence interval 
    )
  path <- paste0("../../results/", tool, "/DEGs/", condition, "_", 
  i, "_gene_DEGs_FDRq0.05_logFC_0.25.txt", sep = "") 
  write.table(
    vTopTable1,
    path,
    sep = "\t",
    row.names = FALSE,
    quote = FALSE
  )
  # increment 
  coef <- coef + 1
}
remove(coef)
```

# PCA
Principal component analysis, or PCA, is a dimensionality reduction method that is often used to reduce the dimensionality of large data sets, by transforming a large set of variables into a smaller one that still contains most of the information in the large set.
```{r PCA}
# Setting the N of genes to use
ntop = length(dge.filtered.norm$genes$gene_id)
# Sorting by the coefficient of variance
means <- rowMeans(voomCounts)
Pvars <- rowVars(voomCounts, useNames = TRUE)
cv2 <- Pvars / means ^ 2
select <-
  order(cv2, decreasing = TRUE)[seq_len(min(ntop, length(cv2)))]
head(select)

highly_variable_exp <- ((voomCounts)[select,])
dim(highly_variable_exp)
# Running PCA
pca_exp <- prcomp(t(highly_variable_exp), scale = F, center = T)
# scale a logical value indicating whether the variables should be scaled
# to have unit variance before the analysis takes place.
# a logical value indicating whether the variables should be shifted to be zero centered.
head(pca_exp$x)[, 1:3]
summary(pca_exp)
# Dataframe with the first 10 PCs
dim1_10 <- data.frame(pca_exp$x[, 1:10])
# Adding metadata
dim1_10$NPID <- rownames(dim1_10)
pcaWithMetadata <- merge(dim1_10, info_with_scale, by = "NPID", all = TRUE)
pcaWithMetadata$group <- pcaWithMetadata$TYPE

# Plotting
ggplot(data = pcaWithMetadata, aes(x = PC1, y = PC2, shape = group, color = group)) +
  geom_point(size = 2.5) +
  theme_bw() +
  scale_color_manual(values = colorbindColors) 

ggplot(data = pcaWithMetadata, aes(x = PC2, y = PC3, shape = group, color = group)) +
  geom_point(size = 2.5) +
  theme_bw() +
  scale_color_manual(values = colorbindColors) 

ggplot(data = pcaWithMetadata, aes(x = PC3, y = PC4, shape = group, color = group)) +
  geom_point(size = 2.5) +
  theme_bw()

ggplot(data = pcaWithMetadata, aes(x = PC5, y = PC6, shape = sex_inferred, color = sex_inferred)) +
  geom_point(size = 2.5) 
```

# Info with PCA output 
```{r}
write.table(pcaWithMetadata, 
            paste0("../../rObjects/", condition, ".metadata.PCA.txt"), 
            quote = FALSE, sep = "\t")

```

# CCA PC1-10 & variables in model 
```{r CCA_PCA}
form_PCA <- ~ TYPE + 
  sex_inferred + 
  batch +
  PCT_CODING_BASES +
  PCT_INTERGENIC_BASES + 
  PCT_INTRONIC_BASES +
  ENO2 +
  RIN +
  PC1 +
  PC2 +
  PC3 +
  PC4 +
  PC5 +
  PC6 +
  PC7 +
  PC8 +
  PC9 +
  PC10 

C = canCorPairs(form_PCA, pcaWithMetadata)
# Plot correlation matrix
cor.mtest <- function(C, ...) {
    C <- as.matrix(C)
    n <- ncol(C)
    p.mat<- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
        for (j in (i + 1):n) {
            tmp <- cor.test(C[, i], C[, j], ...)
            p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
        }
    }
  colnames(p.mat) <- rownames(p.mat) <- colnames(C)
  p.mat
}
# matrix of the p-value of the correlation
p.mat <- cor.mtest(C)
col <- colorRampPalette(c("#4477AA", "#77AADD", "#FFFFFF", "#EE9988", "#BB4444"))
  corrplot(C, method="color", col=col(200),  
         type="upper", order="hclust", 
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         diag=FALSE, col.lim = c(0, 1)
         )
path <- paste0("../../results/", tool ,"/varpart/", condition, ".CCA_PC1_10")
saveToPDF(paste0(path, ".pdf"), width = 20, height = 20)
```


```{r}
sessionInfo()
```